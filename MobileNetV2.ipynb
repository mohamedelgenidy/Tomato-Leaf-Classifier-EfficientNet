{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdGhcklVK48Q"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cqEjeVNeNwOB"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xx3ZlQuKmnA"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "# Import EfficientNet\n",
        "from tensorflow.keras.applications import EfficientNetB4\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "base_data_dir = '/content/drive/MyDrive/tomatoes/leaf_classifier_dataset/'\n",
        "train_dir = os.path.join(base_data_dir, 'train')\n",
        "\n",
        "# تحديد أبعاد الصور وعدد العينات (batch size)\n",
        "# Updated IMG_SIZE for EfficientNetB4\n",
        "IMG_SIZE = (380, 380)\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "# تحميل الداتا من المجلدات\n",
        "# Keras will automatically name classes based on folder names (leaves, no_leaves)\n",
        "# We split the data (80% for training, 20% for testing/validation)\n",
        "train_dataset = image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    validation_split=0.2,  \n",
        "    subset=\"training\",\n",
        "    seed=123,\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "validation_dataset = image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=123,\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "# عرض أسماء الفئات التي تم اكتشافها (يجب أن يطبع: ['leaves', 'no_leaves'])\n",
        "class_names = train_dataset.class_names\n",
        "print(\"Categories found:\", class_names)\n",
        "\n",
        "# تحسين أداء تحميل الداتا\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "# -----------------------------------------------------------------\n",
        "#  بناء المودل (استخدام Transfer Learning)\n",
        "# -----------------------------------------------------------------\n",
        "\n",
        "# تحميل مودل EfficientNetB4\n",
        "# include_top=False يعني أننا لا نريد طبقة التصنيف الأخيرة منه\n",
        "# Use the recommended input shape for EfficientNetB4\n",
        "base_model = EfficientNetB4(input_shape=(380, 380, 3),\n",
        "                         include_top=False,\n",
        "                         weights='imagenet')\n",
        "\n",
        "# \"تجميد\" طبقات المودل الأساسي حتى لا نعيد تدريبها\n",
        "base_model.trainable = False\n",
        "\n",
        "# بناء المودل الخاص بنا\n",
        "inputs = Input(shape=(380, 380, 3))\n",
        "x = base_model(inputs, training=False)\n",
        "x = GlobalAveragePooling2D()(x) # طبقة لتصغير المخرجات\n",
        "x = Dropout(0.2)(x) # طبقة لمنع الـ Overfitting\n",
        "x = Dense(128, activation='relu')(x)\n",
        "\n",
        "# The last layer:\n",
        "# نستخدم 1 نيرون فقط (0 أو 1) و 'sigmoid' لأنه تصنيف ثنائي\n",
        "outputs = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs, outputs)\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# -----------------------------------------------------------------\n",
        "#  train model\n",
        "# -----------------------------------------------------------------\n",
        "print(\"\\n--- Start train---\")\n",
        "# 10 epochs\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=10,\n",
        "    validation_data=validation_dataset\n",
        ")\n",
        "print(\"--- Finsh train---\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "be71FFWda9GI"
      },
      "outputs": [],
      "source": [
        "# save model\n",
        "model_save_path = '/content/drive/MyDrive/tomatoes/leaf_classifier_model.h5'\n",
        "model.save(model_save_path)\n",
        "print(f\"Model saved to: {model_save_path}\")\n",
        "# load model\n",
        "loaded_model = load_model('/content/drive/MyDrive/tomatoes/leaf_classifier_model.h5')\n",
        "print(\"Model loaded from lung_cancer_detector.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K72zc_R3VUfG"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# 1. تحميل المودل الذي قمنا بحفظه\n",
        "model_path = '/content/drive/MyDrive/tomatoes/leaf_classifier_model.h5'\n",
        "model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "# 2. تحديد مسار الصورة التي تريد اختبارها\n",
        "# !!! غيّر هذا المسار إلى صورة جديدة !!!\n",
        "test_image_path = '/content/drive/MyDrive/tomatoes/leaf_classifier_dataset/train/no_leaves/180_IMG_06094608_jpg.rf.22fd94f6831a63029957ddef65d1a2b3.jpg'\n",
        "\n",
        "# 3. تحميل الصورة وتجهيزها\n",
        "img = image.load_img(test_image_path, target_size=IMG_SIZE)\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0) # تحويلها لـ batch\n",
        "\n",
        "prediction = model.predict(img_array)\n",
        "\n",
        "# النتيجة ستكون رقم بين 0 و 1\n",
        "score = prediction[0][0]\n",
        "\n",
        "print(f\"image: {test_image_path}\")\n",
        "print(f\" prediction (Score): {score}\")\n",
        "\n",
        "# (Assume 'leaves' is class 0 and 'no_leaves' is class 1)\n",
        "# إذا كان ['leaves', 'no_leaves']، إذن:\n",
        "if score < 0.5:\n",
        "    print(\"Result: Leaf ✅ (Class: leaves)\")\n",
        "else:\n",
        "    print(\"Result: No leaf ❌ (Class: no_leaves)\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
